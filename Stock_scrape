import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random

headers = {'User-Agent': 'Mozilla/5.0'}

urls = [
    'https://groww.in/us-stocks/nke', 'https://groww.in/us-stocks/ko',
    'https://groww.in/us-stocks/axp', 'https://groww.in/us-stocks/amgn',
    'https://groww.in/us-stocks/aapl', 'https://groww.in/us-stocks/ba',
    'https://groww.in/us-stocks/csco', 'https://groww.in/us-stocks/gs',
    'https://groww.in/us-stocks/ibm', 'https://groww.in/us-stocks/intc',
    'https://groww.in/us-stocks/jpm', 'https://groww.in/us-stocks/mcd',
    'https://groww.in/us-stocks/crm', 'https://groww.in/us-stocks/vz',
    'https://groww.in/us-stocks/v', 'https://groww.in/us-stocks/wmt',
    'https://groww.in/us-stocks/dis'
]

all_data = []

for url in urls:
    print(f"Scraping: {url}")
    try:
        page = requests.get(url, headers=headers, timeout=10)
        page.raise_for_status()
        soup = BeautifulSoup(page.text, 'html.parser')

        company = soup.find('h1')
        price = soup.find('span', {'class': lambda x: x and 'uht141Pri' in x})
        change = soup.find('div', {'class': lambda x: x and 'uht141Day' in x})
        volume_table = soup.find('table')
        volume = volume_table.find_all('td')[1] if volume_table else None

        data = [
            company.text.strip() if company else "N/A",
            price.text.strip() if price else "N/A",
            change.text.strip() if change else "N/A",
            volume.text.strip() if volume else "N/A"
        ]
        all_data.append(data)

    except Exception as e:
        print(f"[ERROR] {url}: {e}")

    time.sleep(random.uniform(2, 5))

df = pd.DataFrame(all_data, columns=["Company", "Price", "Change", "Volume"])
df.to_csv('stocks.csv', index=False)
